{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /home/ptaech/.var/app/com.visualstudio.code/cache/torch/hub/v0.10.0.zip\n",
      "/home/ptaech/Documents/Projects/CSE5523/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ptaech/Documents/Projects/CSE5523/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /home/ptaech/.var/app/com.visualstudio.code/cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torcheval.metrics import BinaryAccuracy, BinaryRecall, BinaryPrecision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from model import Net\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_device('cuda')\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    torch.set_default_device('mps')\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    torch.set_default_device('cpu')\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "torch.manual_seed(0)\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "photometric_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Resize((256, 256)),\n",
    "     transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Resize((256, 256)),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.OxfordIIITPet(\"\", split=\"trainval\", transform=photometric_transform, target_types=\"binary-category\", download=True).__add__(datasets.OxfordIIITPet(\"\", split=\"trainval\", transform=transform, target_types=\"binary-category\", download=True))\n",
    "test = datasets.OxfordIIITPet(\"\", split=\"test\", transform=transform, target_types=\"binary-category\", download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model.pth', map_location=device, weights_only=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "metrics = {\"Accuracy\":BinaryAccuracy(device=device), \"Recall\": BinaryRecall(device=device), \"Precision\":BinaryPrecision(device=device)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True, generator=torch.Generator(device=device).manual_seed(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 10/115] loss: 0.06899387463927269 Accuracy: 0.978 Recall: 0.993 Precision: 0.975 \n",
      "[1, 20/115] loss: 0.0753303935751319 Accuracy: 0.974 Recall: 0.984 Precision: 0.978 \n",
      "[1, 30/115] loss: 0.08010146953165531 Accuracy: 0.973 Recall: 0.983 Precision: 0.978 \n",
      "[1, 40/115] loss: 0.051252171769738196 Accuracy: 0.976 Recall: 0.987 Precision: 0.979 \n",
      "[1, 50/115] loss: 0.07394364848732948 Accuracy: 0.975 Recall: 0.987 Precision: 0.977 \n",
      "[1, 60/115] loss: 0.0698537714779377 Accuracy: 0.975 Recall: 0.985 Precision: 0.978 \n",
      "[1, 70/115] loss: 0.05094455098733306 Accuracy: 0.976 Recall: 0.986 Precision: 0.979 \n",
      "[1, 80/115] loss: 0.06284597590565681 Accuracy: 0.976 Recall: 0.985 Precision: 0.980 \n",
      "[1, 90/115] loss: 0.06458655744791031 Accuracy: 0.976 Recall: 0.986 Precision: 0.979 \n",
      "[1, 100/115] loss: 0.05009535551071167 Accuracy: 0.977 Recall: 0.986 Precision: 0.980 \n",
      "[1, 110/115] loss: 0.05237346701323986 Accuracy: 0.977 Recall: 0.986 Precision: 0.981 \n",
      "[1, 115/115] loss: 0.06682261880487203 Accuracy: 0.977 Recall: 0.986 Precision: 0.981 \n"
     ]
    }
   ],
   "source": [
    "batches = len(trainloader)\n",
    "for epoch in range(1):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device).to(torch.float32)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        for _,metric in metrics.items():\n",
    "            metric.update(outputs, labels.to(torch.long))\n",
    "        if i % 10 == 9 or i == batches - 1:\n",
    "            print(f'[{epoch + 1}, {i + 1}/{batches}] loss: {running_loss / (batches%10 if i == batches-1 else 10)}', end=' ')\n",
    "\n",
    "            for name,metric in metrics.items():\n",
    "                print(f'{name}: {metric.compute():.3f}', end=' ')\n",
    "            print()\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/58] Accuracy: 0.686 Recall: 0.877 Precision: 0.698 \n",
      "[20/58] Accuracy: 0.666 Recall: 0.912 Precision: 0.635 \n",
      "[30/58] Accuracy: 0.724 Recall: 0.878 Precision: 0.762 \n",
      "[40/58] Accuracy: 0.731 Recall: 0.880 Precision: 0.767 \n",
      "[50/58] Accuracy: 0.729 Recall: 0.879 Precision: 0.763 \n",
      "[58/58] Accuracy: 0.715 Recall: 0.874 Precision: 0.748 \n"
     ]
    }
   ],
   "source": [
    "testloader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "for name,metric in metrics.items():\n",
    "    metric.reset()\n",
    "batches = len(testloader)\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    inputs, labels = data\n",
    "    inputs, labels = inputs.to(device), labels.to(device).to(torch.float32)\n",
    "    outputs = model(inputs)\n",
    "    for _,metric in metrics.items():\n",
    "        metric.update(outputs, labels.to(torch.int64))\n",
    "    if i % 10 == 9 or i == batches - 1:\n",
    "        print(f'[{i + 1}/{batches}]', end=' ')\n",
    "        for name,metric in metrics.items():\n",
    "            print(f'{name}: {metric.compute():.3f}', end=' ')\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
